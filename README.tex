\documentclass{amsart}
\usepackage{amsmath,amsthm,amssymb,hyperref,enumerate,verbatimbox}
\title{How to Use AutoDiff}
\author{SeHyoun Ahn}
\date{January 2016}

\begin{document}
\maketitle

\section{Initial Setup}
If you are reading this document, I believe you already want to implement automatic differentiation instead of other methods of numerical differentiation, so I will jump right into how to use it. For comparison between automatic differentiation and other forms of numerical differentiation, see section~\ref{comparison} below. 

\subsection{Compiling mex Files}
This program uses C acceleration to improve on the (intermediate) memory usage and speed of a portion of the program (the biggest difference will be from matrix-vector multiplication). Hence, if the size of the problem is small or the speed does not matter too much, the program can be used without compiling c files. Before this step, C/C++ compiler that is accepted by MATLAB mex needs to be installed. List of compatible compilers can be found at \url{http://www.mathworks.com/support/compilers/R2015b/index.html} Once, a proper compiler has be installed; run \verb1<compile_mex_files.m>1 in MATLAB. This will compile the C code for local OS using the compatible compiler.

\subsection{Adding Class Folder at Startup}
MATLAB defines class structure with folders. Hence, the \verb1@myAD1 needs to be in its search path for the automatic differentiation to work. One way to do this is by just adding the parent folder location of the \verb1@myAD1 folder at the beginning of each session. For example, if the \verb1@myAD1 folder is in \verb1<\home\username\scripts\>1 Then 
\begin{center}
\verb1path(path,'\home\username\scripts\');1
\end{center}
will add the correct parent folder to the search path.\\

However, this requires the addition of the path in every session, and this can be fixed permanently by adding the path permanently to the path file by calling 
 \begin{center}
   \verb1savepath1
 \end{center}
and you would not have to add the path again with each new session.\footnote{In some platforms, you might not be able to \texttt{savepath} unless you run with heightened privileges. Matlab will throw an error/warning message with further instructions.}

\section{A Quick Tutorial}
Suppose you want to find the derivative of $f(\vec{x})$ at some point $\vec{x}_0$, $\left.D_{\vec{x}}f\right|_{\vec{x}_0}$. Then, you would first initialize the values of $\vec{x}$'s at the point $\vec{x}_0$ by calling 
\begin{center}
 \verb1x=myAD(x_0);1
\end{center}
which will create a dual number variable $x$ with values of $x_0$. Then, you can do the operation on the variable $x$ by calling the function $f$.
\begin{center}
  \verb1y=f(x);1
\end{center}
Then, y will contain both the functional value $f(\vec{x}_0)$, and the derivative $\left.D_{\vec{x}}f\right|_{\vec{x}_0}$. You can access them by calling
\begin{center}
  \verb1getvalues(y);1\\
  \verb1getderivs(y);1
\end{center}
This is it! Numerically computing the derivative does not require any coding beyond initializing the variables as a dual number (with the initial call of myAD).
\subsection{Example}
 For example, consider $f(x_1,x_2,x_3)=(x_1^2,x_2^3,x_1\cdot x_3)$ at point $\vec{x}_0=(2,6,4)$. The following code will compute the derivative of $f$ at $\vec{x}_0$, and set the variable $A$ as the derivative matrix.
\begin{align*}
  &\texttt{x=myAD([2;6;4]);}\\
  &\texttt{y=[x(1)\^{}2;x(2)\^{}3;x(1)*x(3)];}\\
  &\texttt{A=getderivs(y);}
\end{align*}
Automatic differentiation will handle more complex combination of operations, as long as each operations are supported. For example, since \verb1spdiags1 and matrix-vector multiplication are supported.
\begin{align*}
  &\texttt{B=spdiags(y,1,3,3);}\\
  &\texttt{z=B*x;}\\
  &\texttt{C=getderivs(z);}
\end{align*}
will compute the derivative of $B\vec{x}$ respect to $\vec{x}$ at $\vec{x}_0$.

\subsection{Supported Functions} The list of supported operations are given in the following table. Since matlab has a lot of functions, not all functions are implemented. If you need functions not yet supported, e-mail \href{mailto:sehyouna@princeton.edu}{sehyouna@princeton.edu}.\footnote{Disclaimer: Obviously, not all functions can be implemented.}\\

\subsubsection{Algebraic Operations}
~\\
\texttt{+} (plus)\\
\texttt{-} (minus)\\
\texttt{.*} (times)\\
\texttt{.\^} (power)\\
\texttt{.\slash} (rdivide)\\
\texttt{.\textbackslash} (ldivide)\\
\texttt{abs}\\
\texttt{exp}\\
\texttt{log}\\
\texttt{sqrt}\\

\subsubsection{Matrix Operations/Functions}~\\
\verb1'1 (ctranspose)\\
\verb1*1 (mtimes)\\
\verb1\1 (mldivide)\\
\verb1/1 (mrdivide)\\
\verb1[A;B]1 (vertcat) where \verb1A1 and \verb1B1 are matrices\\
\verb1[A,B]1 (horzcat) where \verb1A1 and \verb1B1 are matrices\\
\verb1var = A(i:j,k:l)1 (subref) where \verb1A1 is a matrix\footnote{\texttt{end} can be used for subsetting, e.g., \texttt{A(2:end)}}\\
\verb1A(i:j,k:l) = var1 (subasgn) where \verb1A1 is a matrix\\
\verb1cumprod1\\
\verb1cumsum1\\
\verb1diff1\\
\verb1length1\\
\verb1max1\\
\verb1min1\\
\verb1repmat1\\
\verb1reshape1\\
\verb1size1\\
\verb1sort1\\
\verb1spdiags1\\

\subsubsection{Trignometric Functions}~\\
\verb1acos1\\
\verb1asin1\\
\verb1atan1\\
\verb1cos1\\
\verb1sin1\\
\verb1tan1\\
\verb1tanh1\\

\subsubsection{Logical Operations}~\\
\verb1==1\\
\verb1>=1\\
\verb1<=1\\
\verb1>1\\
\verb1<1\\
\verb1isnan1\\

\subsubsection{Etc.}~\\
\verb1disp1\\
\verb1end1\\
\verb1fsolve1\footnote{Check technical notes below to see how to implement vector values problems}

\section{Non-Standard Syntax}
Some function calls require syntactic decisions since there is not a canonical way to do so for the function. There is only one function (fsolve for multiple variables) that require an addition syntactic requirement, but this list of functions might increase in the future. For any function not leasted here, calling the funcition for dual numbers should be the same as that of the usual function call for real numbers.
\subsection{fsolve}
Given $f(\vec{x},\vec{y}): \mathbb{R}^{n+m}\Rightarrow \mathbb{R}^m$ with $\vec{x}\in \mathbb{R}^n$ and $\vec{y}\in \mathbb{R}^m$. The function $f(\cdot)$ needs to have the first $n$-dimension as the unknown values that \texttt{fsolve} will be solving for. This is not too restrictive as a new intermediate function can be made with the variables reordered so that \texttt{fsolve} is solving for the first $n$ variables. Given a function with correct ordering, the syntax of calling \texttt{fsolve} is
\begin{align*}
&\text{\texttt{fsolve(f,x0,y,...)}}
\end{align*}
where \texttt{f} is the function handle, \texttt{x0} is the initial guess, and \texttt{y} is the given parameters/variables (with \texttt{fsolve} options following y). This is more clear with an example. Suppose $x_1, x_2$ are defined implicitely by  
\begin{align*}
  f(x_1,x_2,x_3;a)=\left(\begin{array}{c} x_1^2+x_2+x_3+a^2\\ x_1+x_1x_2+ax_3+\sin(x_3)\end{array}\right)=\vec{0}
\end{align*}
and we want to find the derivatives of $x_1$ and $x_2$ with respect to variables $z_1, z_2$ and $z_3$, where $x_3=z_1z_2+z_3$ and $a=z_1+z_2$ at a point $\vec{z}=(1,2,3)$.
\begin{verbatim}

  z=myAD([1;2;3]);
  f = @(x) [x(1)^2+x(2)+x(3)+x(4)^2;...
            x(1)+x(1)*x(2)+x(3)*x(4)+sin(x(3))];
  y = fsolve(f,[0;0],[z(1)*z(2)+z(3);z(1)+z(2)]);
  y_values = getvalues(y);
  y_derivs = getderivs(y);

\end{verbatim}
Note that even if $a$ is interpreted a parameter of the function (instead of a variable) in the problem, if it is a dual-number, then the function $f$ needs to be treated as a 4-dimensional function with $a$ as a variable.

\section{Points of Potential Speed Gain}
This code was optimized/tuned for our problem in mind. For example, it saves the derivative matrix as a sparse matrix because our problem results in a very sparse derivative matrices. Instead of trying to guess and tune for hypothetical case, I have included a list of points of potential speed gains.
\begin{itemize}
\item (To be implemented in a near future) Scalar-matrix multiplication can be C accelerated.
\item (To be implemented in a near future) I allocate an auxillary storage (of size $<$number of rows$>$) to do a linear-time sorting in matdrivXvecval.c, but this can be changed. The new algorithm will behave better if the resulting vector (from $A\vec{b}$) is sparse.
\item If your problem results in a non-sparse derivative matrix, it will be more efficient to use full matrices instead of sparse matrices. (You will not be able to use C acceleration provided with the package if you use full representation.)
\item Because I believe people do not use cumsum and cumprod that much, I just opted not to optimize this code
too much. They are included for completeness, but they can be further optimized. \texttt{cumprod} uses double loops. It probably can be improved on (or at least written in C). Also, for the second dimension of cumsum/cumprod I just transpose, cumsum in first dimension and then transpose back to get the result.
\item b/A calls either ./ if A is a scalar, or (A'/b')' if A is a matrix. The latter does spurious transposes. Therefore, if possible, the problem should be reformulated to avoid b/A where A is a matrix
\item Concatenations is done through loops because the varargin object can contain both \texttt{myAD} and double array objects. This can be made faster by making the matrices directly if possible instead of calling concatenation.
\end{itemize}

\section{License}
Copyright (c) 2016, SeHyoun Ahn
All rights reserved.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
\begin{itemize}
  \item Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
  \item Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution
\end{itemize}
THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\
\\

This program is based on $<$Automatic Differentiation for Matlab$>$ package by Martin Fink with license:\\
\\


Copyright (c) 2006, Martin Fink
All rights reserved.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
\begin{itemize}
 \item Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
 \item Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution
\end{itemize}

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\\
\\

 With a few majors changes being:
\begin{itemize}
\item Derivative matrices are stored as sparse matrices instead of full matrices
\item Matrices can be defined directly, and other sparse matrix operations, e.g., \texttt{spdiags}, are implemented
\item Matrices multiplication and backslash are implemented
\item fsolve is implemented
\item New C acceleration is written for matrix-vector multiplication
\item C acceleration is rewritten to for sparse storage.
\end{itemize}

\section{How Automatic Differentiation Works}
To be completed.

\section{Comparison to Other Forms of Numerical Differentiation}\label{comparison}
To be completed.
\end{document}
